## 什么是短链接

> 就是把普通网址，转换成比较短的网址。比如：[http://t.cn/RlB2PdD](http://t.cn/RlB2PdD)这种，在微博这些限制字数的应用里。好处不言而喻。短、字符少、美观、便于发布、传播。

    百度短网址[http://dwz.cn/](http://dwz.cn/)  
    谷歌短网址服务[https://goo.gl/](https://goo.gl/)（需科学上网）号称是最快的

## 原理解析

    当我们在浏览器里输入[http://t.cn/RlB2PdD](http://t.cn/RlB2PdD)时

1.  DNS首先解析获得[http://t.cn](http://t.cn/)的`IP`地址
2.  当`DNS`获得`IP`地址以后（比如：74.125.225.72），会向这个地址发送`HTTP``GET`请求，查询短码`RlB2PdD`
3.  [http://t.cn](http://t.cn/)服务器会通过短码`RlB2PdD`获取对应的长 URL
4.  请求通过`HTTP``301`转到对应的长 URL[https://m.helijia.com](https://m.helijia.com/)。

    这里有个小的知识点，为什么要用 301 跳转而不是 302 呐？

> 301 是永久重定向，302 是临时重定向。短地址一经生成就不会变化，所以用 301 是符合`http`语义的。同时对服务器压力也会有一定减少。  
> 但是如果使用了`301`，我们就无法统计到短地址被点击的次数了。而这个点击次数是一个非常有意思的大数据分析数据源。能够分析出的东西非常非常多。所以选择302虽然会增加服务器压力，但是我想是一个更好的选择。

## **如何将长链转换为短链接**

    思路1： 实现一个算法，将长地址转成短地址。实现长和短一一对应。然后再实现它的逆运算，将短地址还能换算回长地址。
    
        假设 短地址的长度为100位。那么它的变化是62的100次方。62=10数字+26大写字母+26小写字母。但是无论这个数多么大，他也不可能容下世界上可能存在的长地址。
    
        如果真有这么一个算法和逆运算，那么基本上现在的压缩软件都可以卸载了，因为世界上所有的信息，都可以被这个算法给压缩到100个字符，然后还能还原回去。这明显是不可能的。
    
        （不要幻想使用压缩算法，对于URL这种不超过100bytes的字符串，压缩算法的压缩比通常都大于1，也就是压缩结果比原来的内容还要长）
    
    思路2： 把长地址转成短地址，但是不存在逆运算。我们需要把短对长的关系存到DB中。通过短查长的时候，需要查DB。
    
        如果真有这么一个转换算法，那必然是会出现碰撞的，也就是多个长地址转成了同一个短地址。 不同的长网址缩短成了同一个短网址，那也做不到还原了。
    
        因为我们无法预知会输入什么样的长地址到这个系统中，所以不可能实现这样一个绝对不碰撞的hash函数。
    
        （不要幻想使用Hash映射，因为Hash冲突是不可控的。当然，我们有解决Hash冲突的N种方法，但是这只会增加系统的复杂度 ）
    
    思路3：用一个hash算法，我承认它会碰撞，碰撞后我再在后面加1，2，3不就行了
    
        当通过这个hash算法算出来之后，可能我们会需要根据 like 查找到 现在应该在后面加1，2，还是3，这个也可能由于输入的长地址集的不确定性。导致生成短链接时间的不确定性。

 同理：随机生成一个短地址，去查找是否用过，用过就再随机，如此往复，直到随机到一个没用过的短地址。也是存在生成短链接时间的不确定性。



正确做法：

#     思路1： **自增序列算法**

​    设置 id 自增，一个 10进制 id 对应一个 62进制的数值，1对1，也就不会出现重复的情况。这个利用的就是低进制转化为高进制时，字符数会减少的特性。

​    如下图：十进制 10000，对应不同进制的字符表示 ：

![](../../image/up-c8dd9a8adc238136f9b9a8399399776184f-1591507883016.png)

​    短址的长度一般设为 6 位，而每一位是由`[a - z, A - Z, 0 - 9]`总共 62 个字母组成的，所以 6 位的话，总共会有 62^6 ~= 568亿种组合，基本上够用了。

​    通过发号策略，给每一个过来的长地址，发一个号即可，小型系统直接用mysql的自增索引就搞定了。如果是大型应用，可以考虑各种分布式key-value系统做发号器。不停的自增就行了。

 **_如何保证同一个长地址，每次转出来都是一样的短地址_ ？**

​    上述发号原理中，是不判断长地址是否已经转过的。也就是说用拿着百度首页地址来转，我给返回一个：http://xx.xx/abc，过一段时间你再来转，我会给你另一个地址：http://xx.xx/xyz

由于出现了 一长对多短，浪费了空间。如果考虑 使用一个全量的 K-V 存储来保证不会 一长对多短，但是这个  KV存储本身就是浪费大量空间，而且是 大空间换小空间 ，不划算。

我们做不到真正的一一对应，那么适当地打个折扣：

​     用key-value存储，保存“最近”生成的长对短的一个对应关系。注意是“最近”，也就是说，不保存全量的长对短的关系，而只保存最近的。比如采用一小时过期的机制来实现LRU淘汰。

 长转短的流程变成这样：

>         1 在这个“最近”表中查看一下，看长地址有没有对应的短地址
>
>         2 有就直接返回，并且将这个key-value对的过期时间再延长成一小时
>
>         3 如果没有，就通过发号器生成一个短地址，并且将这个“最近”表中，过期时间为1小时

        当一个地址被频繁使用，那么它会一直在这个key-value表中，总能返回当初生成那个短地址，不会出现重复的问题。如果它使用并不频繁，那么长对短的key会过期，LRU机制自动就会淘汰掉它。
    
        这不能保证100%的同一个长地址一定能转出同一个短地址，比如你拿一个"冷门"的url，每间隔1小时来转一次，你会得到不同的短地址，但是这种情况，是在能容忍的范围内的。
    
    **_如何保证发号器的高并发和高可用？_**
    
         如果做成分布式的，那么多节点要保持同步加1，多点同时写入。

可以考虑实现两个发号器，一个发单号，一个发双号，这样就变单点为多点了。

        依次类推，我们可以实现1000个逻辑发号器，分别发尾号为0到999的号。每发一个号，每个发号器加1000，而不是加1。这些发号器独立工作，互不干扰即可。而且在实现上，也可以先是逻辑的，真的压力变大了，再拆分成独立的物理机器单元。

####     自增算法流程图

![](../../image/up-626fc87bbf62a88e43cd90d7d45b5b52055-1591507889347.png)

插入记录，得到 id，再进行 进制换算得到 短链接，再把 短链接 更新至 刚刚插入的记录。

**_允许用户自定义短链，此时该如何实现呢？_**

​    自增序列算法 短链接 是和 id 绑定的， 如果允许自定义短码就会占用当前id之后的短码，之后的 id 要生成短码的时候就发现在前面的记录中短码已经被用了。

​    解决方法：

>         1.数据库增加一个类型 type 字段，用来标记短码是用户自定义生成的，还是系统自动生成的。
>
>         2.用户自定义短码，把它的类型标记自定义，并插入一条记录。
>
>         3.根据 id 计算 短码时，如果发现计算出的短码被之前的记录给占用了，那么就从 类型为自定义的记录里选取出一条记录，用该记录的 id 去计算短码。
>
>         这样既可以区分：哪些长连接是用户自己定义还是系统自动生成的，还可以不浪费被自定义短码占用的数据库记录 id 对应的短码地址。

![](../../image/up-12a7e6aaaf3b9ebc823b120d1bfe05f1680-1591507893233.png)

####     # DB设计

      只需要一张表，存放短码与原网址的映射关系，其他一些属性比如原网址的sha1码，过期时间等保存好即可。当然短码和sha1字段都要加上唯一索引，保证唯一性的同时提高查询效率。
    
    links 表

| 字段       | 含义                            |
| ---------- | ------------------------------- |
| id         | link_id                         |
| url        | 长连接                          |
| keyword    | 短链接码                        |
| type       | 系统: “system” 自定义: “custom” |
| insert_at  | 插入时间                        |
| updated_at | 更新时间                        |

    自增算法，可以保留了若干位的短码，例如 1 到 2 位的 短码，一开始可以从三位的短码开始生成。

| 位数 | 个数      | 区间                    |
| ---- | --------- | ----------------------- |
| 1位  | 62        | 0 - 61                  |
| 2位  | 3844      | 62 - 3843               |
| 3位  | 约 23万   | 3844 - 238327           |
| 4位  | 约 1400万 | 238328 - 14776335       |
| 5位  | 约 9.1亿  | 14776336 - 916132831    |
| 6位  | 约 568亿  | 916132832 - 56800235583 |

####     # Redis设计

        若想短链接服务达到低延迟高并发的目标，Redis在很多环节都可以起到关键作用。  
**1. 自增长序列**  
        通过Redis的 `incr` 方法可以很容易的实现全局自增长序列，但前提是Redis的高可用。

        如果Redis挂了序列从哪里开始呢？当然是从DB中拿咯，怎么拿？

`    方式一：DB表中新增一个字段，每次都存入生成短码基于的全局序号值。获取到最新的一个全局序号值,Redis在此基础上+1即可；`

`    方式二：直接从DB中获取最新的短码，然后逆向计算出全局序号值，Redis在此基础上+1即可。`

**2. 长网址的Hash表**  
        在Redis中存入热点网址的hash映射数据，注意，这里说的是热点网址而且不是全量网址，实现者需要有所取舍。或者没有命中的就产生新的短码（会导致同址不同码），或者没有命中就到数据库查询，保证强一致的同址同码。

**3. 短码与长网址的映射表**  
        在Redis中存入热点网址的映射，在短网址还原的请求处理中可以快速的查询到原网址。所以这个点的缓存是必须的。

**可能需要考虑的问题：**

**1. 字符超长问题**  
        即使到了10亿(Billion)转换而成的62进制也无非是6位字符，所以长度基本不在考虑范围内，这个范围足够使用了。

**2. 短码安全问题**  
        按照算法从0-61都是1位字符，然后2位、3位...这样的话很容易被人发现规律并进行攻击，当然防御手段很多，请求签名之类的安全验证手段不在本文讨论范围内。  
        首先计数器可以从一个比较大的随机中间值开始，比如从`10000`开始计数，他的62进制是 `2Bi` 3位的字符串；  
        然后采用一些校验位算法(比如Luhn改进一下)，计算出1位校验位拼接起来，4位短码，这样可以排除一定的安全风险；  
        再加点安全料的话，可以在62进制的转换过程中把排序好的62个字母数字随机打乱，比如`ABCD1234`打乱成`1BC43A2D`, 转换的62进制也就更难hack了；  
        最后如果仍不放心，还可以在某些位置（比如1，3，5）插入随机数，让人无法看出规律来也可以达到良好的效果。

 **3. 自增算法是否完美无缺**  
    自增算法 随着序号的自增，码越来越长，到了很大的数值后没有办法循环往复，让码重新变短！

#     思路二：hash

> 1.  将长网址`md5`生成 32 位签名串,分为 4 段, 每段 8 个字节
> 2.  对这四段循环处理, 取 8 个字节, 将他看成 16 进制串与 0x3fffffff(30位1) 与操作, 即超过 30 位的忽略处理
> 3.  这 30 位分成 6 段, 每 5 位的数字作为字母表的索引取得特定字符, 依次进行获得 6 位字符串
> 4.  总的`md5`串可以获得 4 个 6 位串,取里面的任意一个就可作为这个长 url 的短 url 地址

 这个算法在服务量不大的情况下hash碰撞的概率尚可以接受，一定量的压测效果也还算理想。因为有4个hash可选项，即使碰撞到了还有其他3次机会去避免。但是如果作为基础服务，在使用方调用量级无法估量无法保证短链接绝对可用的情况下，这个算法还是有很大的隐患.

###     两种算法对比

​    第一种算法的好处就是简单好理解，永不重复。但是短码的长度不固定，随着 id 变大从一位长度开始递增。如果非要让短码长度固定也可以就是让 id 从指定的数字开始递增就可以了。百度短网址用的这种算法。

​    第二种算法，存在碰撞（重复）的可能性，虽然几率很小。短码位数是比较固定的。不会从一位长度递增到多位的。据说微博使用的这种算法。 如果业务所需的短网址有效期相对较短，通过批处理定期清洗掉，此时算法二  不失为一种可选方案。